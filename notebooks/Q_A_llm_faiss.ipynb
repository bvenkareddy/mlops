{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrKNraCs/OXYYiNAU3VUoz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xQ4NrSVygd7","executionInfo":{"status":"ok","timestamp":1687583105717,"user_tz":420,"elapsed":16416,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"ddd6d53a-e857-4a85-b573-a69f6f3e39ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.212-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n","Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n","Collecting langchainplus-sdk>=0.0.17 (from langchain)\n","  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, langchain\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 langchain-0.0.212 langchainplus-sdk-0.0.17 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["pip install faiss-cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxI-jRrJysFF","executionInfo":{"status":"ok","timestamp":1687583145096,"user_tz":420,"elapsed":7495,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"9e68bbe5-2068-4335-9a48-aa774c593d23"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.7.4\n"]}]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTRgkY890AvT","executionInfo":{"status":"ok","timestamp":1687583472079,"user_tz":420,"elapsed":6724,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"0d885534-927a-4bed-bfc1-39169b22d60c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pypdf\n","  Downloading pypdf-3.11.0-py3-none-any.whl (256 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.3/256.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-3.11.0\n"]}]},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcycykgF0SiL","executionInfo":{"status":"ok","timestamp":1687583547505,"user_tz":420,"elapsed":7034,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"0e72a48e-cab2-4fdf-a87a-3e4653864f86"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.8\n"]}]},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPR71teO0git","executionInfo":{"status":"ok","timestamp":1687583601661,"user_tz":420,"elapsed":6874,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"8b00fe6f-466b-4972-cec1-61770e6a339d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]}]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzQ3vMwXyS3M","executionInfo":{"status":"ok","timestamp":1687583849967,"user_tz":420,"elapsed":20096,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"110b1748-f6cf-4dee-ab7f-9af8e76587f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["13: Learning Apache Spark with Python\n","Spark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it\n","interactively from the Scala, Python and R shells.\n","3. Generality\n","Combine SQL, streaming, and complex analytics.\n","Spark powers a stack of libraries including SQL and\n","41: Learning Apache Spark with Python\n","4.3 Architecture\n","4.4 How Spark Works?\n","Spark has a small code base and the system is divided in various layers. Each layer has some responsibilities.\n","The layers are independent of each other.\n","The ﬁrst layer is the interpreter, Spark uses a Scala interpreter, with som\n"]}],"source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = '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'\n","\n","# Uncomment the following line if you need to initialize FAISS with no AVX2 optimization\n","# os.environ['FAISS_NO_AVX2'] = '1'\n","\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","# from langchain.document_loaders import TextLoader\n","\n","# from langchain.document_loaders import TextLoader\n","\n","# loader = TextLoader(\"/content/sample_data/pyspark.pdf\")\n","# documents = loader.load()\n","# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n","# docs = text_splitter.split_documents(documents)\n","\n","from langchain.document_loaders import PyPDFLoader\n","\n","loader = PyPDFLoader(\"/content/sample_data/pyspark.pdf\")\n","pages = loader.load_and_split()\n","\n","faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n","docs = faiss_index.similarity_search(\"What is SPARKSQL and how does it work?\", k=2)\n","for doc in docs:\n","    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])\n","\n","\n","# embeddings = OpenAIEmbeddings()\n","# db = FAISS.from_documents(docs, embeddings)\n","\n","# query = \"What did the president say about Ketanji Brown Jackson\"\n","# docs = db.similarity_search(query)\n","\n","# print(docs[0].page_content)\n"]},{"cell_type":"code","source":["from langchain.chains.question_answering import load_qa_chain\n","from langchain.llms import OpenAI"],"metadata":{"id":"vZudNSQz4Fqz","executionInfo":{"status":"ok","timestamp":1687584533068,"user_tz":420,"elapsed":277,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["OPENAI_API_KEY='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'"],"metadata":{"id":"Ca-icubm4wda","executionInfo":{"status":"ok","timestamp":1687584723520,"user_tz":420,"elapsed":1,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n","chain = load_qa_chain(llm, chain_type=\"stuff\")\n","query='What is SPARKSQL and how does it work?'"],"metadata":{"id":"_kqsjTW04Rre","executionInfo":{"status":"ok","timestamp":1687584774689,"user_tz":420,"elapsed":255,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["docs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9awoVEq5LNO","executionInfo":{"status":"ok","timestamp":1687584821952,"user_tz":420,"elapsed":245,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"d7b85ee6-2eab-48bd-dba9-b2f2df6db7cf"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(page_content='Learning Apache Spark with Python\\nSpark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it\\ninteractively from the Scala, Python and R shells.\\n3. Generality\\nCombine SQL, streaming, and complex analytics.\\nSpark powers a stack of libraries including SQL and DataFrames, MLlib for machine learning,\\nGraphX, and Spark Streaming. You can combine these libraries seamlessly in the same application.\\nFig. 2: The Spark stack\\n4. Runs Everywhere\\nSpark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including\\nHDFS, Cassandra, HBase, and S3.\\n8 Chapter 2. Why Spark with Python ?', metadata={'source': '/content/sample_data/pyspark.pdf', 'page': 13}),\n"," Document(page_content='Learning Apache Spark with Python\\n4.3 Architecture\\n4.4 How Spark Works?\\nSpark has a small code base and the system is divided in various layers. Each layer has some responsibilities.\\nThe layers are independent of each other.\\nThe ﬁrst layer is the interpreter, Spark uses a Scala interpreter, with some modiﬁcations. As you enter\\nyour code in spark console (creating RDD’s and applying operators), Spark creates a operator graph. When\\nthe user runs an action (like collect), the Graph is submitted to a DAG Scheduler. The DAG scheduler\\ndivides operator graph into (map and reduce) stages. A stage is comprised of tasks based on partitions of\\nthe input data. The DAG scheduler pipelines operators together to optimize the graph. For e.g. Many map\\noperators can be scheduled in a single stage. This optimization is key to Sparks performance. The ﬁnal\\nresult of a DAG scheduler is a set of stages. The stages are passed on to the Task Scheduler. The task\\nscheduler launches tasks via cluster manager. (Spark Standalone/Yarn/Mesos). The task scheduler doesn’t\\nknow about dependencies among stages.\\n36 Chapter 4. An Introduction to Apache Spark', metadata={'source': '/content/sample_data/pyspark.pdf', 'page': 41})]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["answer = chain.run(input_documents=docs, question=query)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxKl_ppt4LOH","executionInfo":{"status":"ok","timestamp":1687584781840,"user_tz":420,"elapsed":4540,"user":{"displayName":"Venka Reddy","userId":"10877147519816262591"}},"outputId":"2f00c78b-f2fc-4efc-d471-8502cb00f6e9"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":[" SparkSQL is a library that allows users to combine SQL, streaming, and complex analytics. It is part of the Spark stack and is used to access diverse data sources including HDFS, Cassandra, HBase, and S3. It works by creating an operator graph when the user enters code in the Spark console, which is then submitted to a DAG Scheduler. The DAG Scheduler divides the operator graph into stages and tasks based on partitions of the input data. The stages are then passed on to the Task Scheduler, which launches tasks via the cluster manager.\n"]}]}]}